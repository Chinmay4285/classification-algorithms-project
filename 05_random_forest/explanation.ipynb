{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Random Forest Classification: A Complete Guide\n",
    "\n",
    "Welcome to your comprehensive guide to **Random Forest classification**! This notebook will teach you about one of the most powerful and popular ensemble learning algorithms.\n",
    "\n",
    "## What You'll Learn\n",
    "1. **Ensemble Learning Concept**: Why multiple models are better than one\n",
    "2. **Random Forest Algorithm**: How it builds multiple decision trees\n",
    "3. **Bootstrap Sampling**: Creating diverse training sets\n",
    "4. **Feature Randomness**: Why we don't use all features at each split\n",
    "5. **Voting Mechanism**: How predictions are combined\n",
    "6. **Bias-Variance Tradeoff**: Understanding overfitting reduction\n",
    "7. **Feature Importance**: Measuring variable significance\n",
    "8. **Practical Implementation**: Real-world applications and tuning\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wisdom-of-crowds",
   "metadata": {},
   "source": [
    "## 1. The Wisdom of Crowds: Why Ensembles Work\n",
    "\n",
    "### Real-World Analogy: Guessing Jelly Beans\n",
    "\n",
    "Imagine a jar with 1000 jelly beans. If you ask:\n",
    "\n",
    "**One Expert**: Might guess 750 (could be way off)\n",
    "\n",
    "**100 Random People**: \n",
    "- Person 1: 890\n",
    "- Person 2: 1100\n",
    "- Person 3: 950\n",
    "- ...\n",
    "- **Average of all guesses**: Often very close to 1000!\n",
    "\n",
    "This is the **wisdom of crowds** - individual errors cancel out when you average many independent estimates.\n",
    "\n",
    "### Machine Learning Analogy\n",
    "\n",
    "**Single Decision Tree**: \n",
    "- Might overfit to specific patterns in training data\n",
    "- Sensitive to small changes in data\n",
    "- Can create overly complex rules\n",
    "\n",
    "**Random Forest (Many Trees)**:\n",
    "- Each tree sees slightly different data\n",
    "- Each tree makes different mistakes\n",
    "- **Average prediction** is more robust and accurate\n",
    "\n",
    "### Key Insight\n",
    "\n",
    "ðŸŒ³ + ðŸŒ³ + ðŸŒ³ + ... + ðŸŒ³ = ðŸŒ² (A stronger forest!)\n",
    "\n",
    "**Individual trees are weak and prone to overfitting, but together they create a strong, generalizable model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.datasets import make_classification, load_iris\n",
    "from utils.data_utils import load_titanic_data\n",
    "from utils.evaluation import ModelEvaluator\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"[START] Random Forest Classification Tutorial\")\n",
    "print(\"All libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "algorithm-steps",
   "metadata": {},
   "source": [
    "## 2. How Random Forest Works: Step-by-Step\n",
    "\n",
    "Random Forest combines two key randomization techniques:\n",
    "\n",
    "### Step 1: Bootstrap Sampling (Bagging)\n",
    "\n",
    "For each tree, create a **bootstrap sample**:\n",
    "- Randomly sample N observations **with replacement** from the original training set\n",
    "- Each tree sees a slightly different dataset\n",
    "- About 63% of original samples appear in each bootstrap sample\n",
    "- About 37% are \"out-of-bag\" (OOB) samples\n",
    "\n",
    "### Step 2: Feature Randomness\n",
    "\n",
    "At each split in each tree:\n",
    "- Instead of considering all features, randomly select a subset\n",
    "- Typical choices: âˆš(total_features) or logâ‚‚(total_features)\n",
    "- Find the best split among only these randomly selected features\n",
    "\n",
    "### Step 3: Build Multiple Trees\n",
    "\n",
    "- Build many decision trees (typically 100-1000)\n",
    "- Each tree is trained on different data with different feature subsets\n",
    "- Trees are typically grown deep (high variance, low bias)\n",
    "\n",
    "### Step 4: Combine Predictions\n",
    "\n",
    "**For Classification**:\n",
    "- Each tree votes for a class\n",
    "- Final prediction = majority vote\n",
    "- Confidence = percentage of trees voting for winning class\n",
    "\n",
    "**For Regression**:\n",
    "- Each tree predicts a value\n",
    "- Final prediction = average of all predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrate-bootstrap",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate bootstrap sampling\n",
    "print(\"=== BOOTSTRAP SAMPLING DEMONSTRATION ===\")\n",
    "print()\n",
    "\n",
    "# Create a small dataset to show bootstrap sampling\n",
    "np.random.seed(42)\n",
    "original_data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "n_samples = len(original_data)\n",
    "\n",
    "print(f\"Original dataset: {original_data}\")\n",
    "print(f\"Dataset size: {n_samples}\")\n",
    "print()\n",
    "\n",
    "# Generate several bootstrap samples\n",
    "n_bootstrap_samples = 5\n",
    "bootstrap_samples = []\n",
    "oob_samples = []\n",
    "\n",
    "for i in range(n_bootstrap_samples):\n",
    "    # Bootstrap sampling with replacement\n",
    "    bootstrap_indices = np.random.choice(n_samples, size=n_samples, replace=True)\n",
    "    bootstrap_sample = original_data[bootstrap_indices]\n",
    "    \n",
    "    # Out-of-bag samples (not selected)\n",
    "    oob_indices = np.setdiff1d(range(n_samples), np.unique(bootstrap_indices))\n",
    "    oob_sample = original_data[oob_indices]\n",
    "    \n",
    "    bootstrap_samples.append(bootstrap_sample)\n",
    "    oob_samples.append(oob_sample)\n",
    "    \n",
    "    print(f\"Bootstrap Sample {i+1}: {bootstrap_sample}\")\n",
    "    print(f\"  Unique values: {np.unique(bootstrap_sample)} ({len(np.unique(bootstrap_sample))}/{n_samples})\")\n",
    "    print(f\"  Out-of-bag:   {oob_sample} ({len(oob_sample)}/{n_samples})\")\n",
    "    print(f\"  OOB percentage: {len(oob_sample)/n_samples*100:.1f}%\")\n",
    "    print()\n",
    "\n",
    "# Calculate average OOB percentage\n",
    "avg_oob_pct = np.mean([len(oob)/n_samples*100 for oob in oob_samples])\n",
    "print(f\"Average Out-of-Bag percentage: {avg_oob_pct:.1f}%\")\n",
    "print(f\"Theoretical expectation: ~37%\")\n",
    "print()\n",
    "print(\"Key Insight: Each tree sees different data, making them diverse!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature-randomness-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate feature randomness\n",
    "print(\"=== FEATURE RANDOMNESS DEMONSTRATION ===\")\n",
    "print()\n",
    "\n",
    "# Load a dataset with multiple features\n",
    "X_train, X_test, y_train, y_test, feature_names = load_titanic_data()\n",
    "n_features = len(feature_names)\n",
    "\n",
    "print(f\"Dataset features ({n_features} total): {feature_names}\")\n",
    "print()\n",
    "\n",
    "# Show feature subsets for different nodes\n",
    "n_examples = 5\n",
    "max_features_sqrt = int(np.sqrt(n_features))\n",
    "max_features_log = int(np.log2(n_features))\n",
    "\n",
    "print(f\"Typical max_features choices:\")\n",
    "print(f\"  sqrt({n_features}) = {max_features_sqrt}\")\n",
    "print(f\"  log2({n_features}) = {max_features_log}\")\n",
    "print()\n",
    "\n",
    "print(f\"Example feature subsets (using sqrt = {max_features_sqrt} features):\")\n",
    "np.random.seed(42)\n",
    "for i in range(n_examples):\n",
    "    selected_indices = np.random.choice(n_features, size=max_features_sqrt, replace=False)\n",
    "    selected_features = [feature_names[idx] for idx in selected_indices]\n",
    "    print(f\"  Node {i+1}: {selected_features}\")\n",
    "\n",
    "print()\n",
    "print(\"Key Insight: Each split considers only a random subset of features,\")\n",
    "print(\"reducing correlation between trees and preventing overfitting!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-vs-ensemble",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare single tree vs random forest\n",
    "print(\"=== SINGLE TREE vs RANDOM FOREST COMPARISON ===\")\n",
    "print()\n",
    "\n",
    "# Create models\n",
    "single_tree = DecisionTreeClassifier(random_state=42)\n",
    "random_forest = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_features='sqrt',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train models\n",
    "single_tree.fit(X_train, y_train)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "tree_train_pred = single_tree.predict(X_train)\n",
    "tree_test_pred = single_tree.predict(X_test)\n",
    "rf_train_pred = random_forest.predict(X_train)\n",
    "rf_test_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Calculate accuracies\n",
    "tree_train_acc = accuracy_score(y_train, tree_train_pred)\n",
    "tree_test_acc = accuracy_score(y_test, tree_test_pred)\n",
    "rf_train_acc = accuracy_score(y_train, rf_train_pred)\n",
    "rf_test_acc = accuracy_score(y_test, rf_test_pred)\n",
    "\n",
    "print(\"Performance Comparison:\")\n",
    "print(f\"Single Decision Tree:\")\n",
    "print(f\"  Training Accuracy: {tree_train_acc:.3f}\")\n",
    "print(f\"  Test Accuracy:     {tree_test_acc:.3f}\")\n",
    "print(f\"  Overfitting Gap:   {tree_train_acc - tree_test_acc:.3f}\")\n",
    "print()\n",
    "print(f\"Random Forest:\")\n",
    "print(f\"  Training Accuracy: {rf_train_acc:.3f}\")\n",
    "print(f\"  Test Accuracy:     {rf_test_acc:.3f}\")\n",
    "print(f\"  Overfitting Gap:   {rf_train_acc - rf_test_acc:.3f}\")\n",
    "print()\n",
    "print(f\"Improvement in test accuracy: {rf_test_acc - tree_test_acc:+.3f}\")\n",
    "print(f\"Reduction in overfitting: {(tree_train_acc - tree_test_acc) - (rf_train_acc - rf_test_acc):+.3f}\")\n",
    "\n",
    "# Cross-validation for more robust comparison\n",
    "tree_cv_scores = cross_val_score(single_tree, X_train, y_train, cv=5)\n",
    "rf_cv_scores = cross_val_score(random_forest, X_train, y_train, cv=5)\n",
    "\n",
    "print()\n",
    "print(\"Cross-Validation Results (5-fold):\")\n",
    "print(f\"Single Tree: {tree_cv_scores.mean():.3f} (+/- {tree_cv_scores.std() * 2:.3f})\")\n",
    "print(f\"Random Forest: {rf_cv_scores.mean():.3f} (+/- {rf_cv_scores.std() * 2:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bias-variance",
   "metadata": {},
   "source": [
    "## 3. The Bias-Variance Tradeoff\n",
    "\n",
    "Understanding why Random Forest works requires understanding the **bias-variance tradeoff**:\n",
    "\n",
    "### Single Decision Tree:\n",
    "- **Low Bias**: Can fit complex patterns\n",
    "- **High Variance**: Small changes in data â†’ very different trees\n",
    "- **Result**: Often overfits\n",
    "\n",
    "### Random Forest:\n",
    "- **Low Bias**: Still fits complex patterns (deep trees)\n",
    "- **Reduced Variance**: Averaging reduces prediction variability\n",
    "- **Result**: Better generalization\n",
    "\n",
    "### Mathematical Insight:\n",
    "\n",
    "If you have N independent models with variance ÏƒÂ²:\n",
    "- **Average variance** = ÏƒÂ²/N\n",
    "- **As N increases**, variance decreases!\n",
    "\n",
    "**Key**: Trees must be somewhat **uncorrelated** for this to work effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variance-demonstration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate variance reduction\n",
    "print(\"=== VARIANCE REDUCTION DEMONSTRATION ===\")\n",
    "print()\n",
    "\n",
    "# Create multiple bootstrap samples and train trees\n",
    "n_trees_to_test = [1, 5, 10, 25, 50, 100, 200]\n",
    "n_experiments = 20  # Repeat experiments to measure variance\n",
    "\n",
    "results = []\n",
    "\n",
    "for n_trees in n_trees_to_test:\n",
    "    experiment_accuracies = []\n",
    "    \n",
    "    for exp in range(n_experiments):\n",
    "        # Create Random Forest with different random states\n",
    "        rf = RandomForestClassifier(\n",
    "            n_estimators=n_trees,\n",
    "            max_features='sqrt',\n",
    "            random_state=42 + exp  # Different random state for each experiment\n",
    "        )\n",
    "        \n",
    "        rf.fit(X_train, y_train)\n",
    "        pred = rf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, pred)\n",
    "        experiment_accuracies.append(accuracy)\n",
    "    \n",
    "    mean_acc = np.mean(experiment_accuracies)\n",
    "    std_acc = np.std(experiment_accuracies)\n",
    "    \n",
    "    results.append({\n",
    "        'n_trees': n_trees,\n",
    "        'mean_accuracy': mean_acc,\n",
    "        'std_accuracy': std_acc,\n",
    "        'min_accuracy': np.min(experiment_accuracies),\n",
    "        'max_accuracy': np.max(experiment_accuracies)\n",
    "    })\n",
    "    \n",
    "    print(f\"Trees: {n_trees:3d} | Mean Acc: {mean_acc:.3f} | Std: {std_acc:.3f} | Range: [{np.min(experiment_accuracies):.3f}, {np.max(experiment_accuracies):.3f}]\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print()\n",
    "print(\"Key Observations:\")\n",
    "print(f\"  Variance with 1 tree:   {results_df.iloc[0]['std_accuracy']:.4f}\")\n",
    "print(f\"  Variance with 200 trees: {results_df.iloc[-1]['std_accuracy']:.4f}\")\n",
    "print(f\"  Variance reduction:      {results_df.iloc[0]['std_accuracy'] / results_df.iloc[-1]['std_accuracy']:.1f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-variance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize variance reduction\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot 1: Accuracy vs Number of Trees\n",
    "ax1 = axes[0]\n",
    "ax1.errorbar(results_df['n_trees'], results_df['mean_accuracy'], \n",
    "             yerr=results_df['std_accuracy'], \n",
    "             marker='o', capsize=5, capthick=2, linewidth=2, markersize=8)\n",
    "ax1.set_xlabel('Number of Trees')\n",
    "ax1.set_ylabel('Test Accuracy')\n",
    "ax1.set_title('Accuracy vs Number of Trees\\n(Error bars show standard deviation)')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xscale('log')\n",
    "\n",
    "# Plot 2: Variance Reduction\n",
    "ax2 = axes[1]\n",
    "ax2.plot(results_df['n_trees'], results_df['std_accuracy'], 'o-', linewidth=2, markersize=8)\n",
    "ax2.set_xlabel('Number of Trees')\n",
    "ax2.set_ylabel('Standard Deviation of Accuracy')\n",
    "ax2.set_title('Variance Reduction with More Trees')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_xscale('log')\n",
    "\n",
    "# Add annotations\n",
    "ax2.annotate(f'High Variance\\n(Ïƒ = {results_df.iloc[0][\"std_accuracy\"]:.3f})', \n",
    "             xy=(results_df.iloc[0]['n_trees'], results_df.iloc[0]['std_accuracy']),\n",
    "             xytext=(10, 50), textcoords='offset points',\n",
    "             bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.7),\n",
    "             arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "\n",
    "ax2.annotate(f'Low Variance\\n(Ïƒ = {results_df.iloc[-1][\"std_accuracy\"]:.3f})', \n",
    "             xy=(results_df.iloc[-1]['n_trees'], results_df.iloc[-1]['std_accuracy']),\n",
    "             xytext=(-50, 30), textcoords='offset points',\n",
    "             bbox=dict(boxstyle='round,pad=0.5', fc='lightgreen', alpha=0.7),\n",
    "             arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Interpretation:\")\n",
    "print(\"1. As we add more trees, accuracy stabilizes at a higher level\")\n",
    "print(\"2. Variance (unpredictability) decreases significantly\")\n",
    "print(\"3. Diminishing returns: Most improvement comes from first 50-100 trees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature-importance",
   "metadata": {},
   "source": [
    "## 4. Feature Importance in Random Forest\n",
    "\n",
    "Random Forest provides excellent **feature importance** measurements:\n",
    "\n",
    "### How it works:\n",
    "\n",
    "1. **For each tree**: Calculate how much each feature decreases impurity when used for splitting\n",
    "2. **Average across all trees**: Get mean importance for each feature\n",
    "3. **Normalize**: Make importances sum to 1\n",
    "\n",
    "### Advantages over single tree importance:\n",
    "\n",
    "- **More stable**: Less sensitive to outliers and noise\n",
    "- **More reliable**: Based on many trees, not just one\n",
    "- **Less biased**: Feature randomness reduces bias toward certain features\n",
    "\n",
    "### Types of Feature Importance:\n",
    "\n",
    "1. **Impurity-based** (default): Based on decrease in node impurity\n",
    "2. **Permutation-based**: Based on decrease in accuracy when feature is shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature-importance-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature importance\n",
    "print(\"=== FEATURE IMPORTANCE ANALYSIS ===\")\n",
    "print()\n",
    "\n",
    "# Train a Random Forest with more trees for stable importance estimates\n",
    "rf_importance = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    max_features='sqrt',\n",
    "    random_state=42\n",
    ")\n",
    "rf_importance.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importance = rf_importance.feature_importances_\n",
    "feature_std = np.std([tree.feature_importances_ for tree in rf_importance.estimators_], axis=0)\n",
    "\n",
    "# Create importance DataFrame\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importance,\n",
    "    'Std': feature_std\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importance Ranking:\")\n",
    "print(\"Rank | Feature           | Importance | Std Dev\")\n",
    "print(\"-\" * 50)\n",
    "for i, (_, row) in enumerate(importance_df.iterrows(), 1):\n",
    "    print(f\"{i:2d}   | {row['Feature']:<15} | {row['Importance']:.4f}     | {row['Std']:.4f}\")\n",
    "\n",
    "print()\n",
    "print(f\"Top 3 features account for {importance_df.head(3)['Importance'].sum():.1%} of total importance\")\n",
    "print(f\"All features with importance > 0.05: {(importance_df['Importance'] > 0.05).sum()} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Bar chart with error bars\n",
    "ax1 = axes[0]\n",
    "y_pos = range(len(importance_df))\n",
    "bars = ax1.barh(y_pos, importance_df['Importance'], xerr=importance_df['Std'], \n",
    "                capsize=3, alpha=0.8, color='skyblue', edgecolor='navy')\n",
    "ax1.set_yticks(y_pos)\n",
    "ax1.set_yticklabels(importance_df['Feature'])\n",
    "ax1.set_xlabel('Feature Importance')\n",
    "ax1.set_title('Random Forest Feature Importance\\n(with standard deviation)')\n",
    "ax1.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, importance) in enumerate(zip(bars, importance_df['Importance'])):\n",
    "    width = bar.get_width()\n",
    "    ax1.text(width + importance_df.iloc[i]['Std'] + 0.005, bar.get_y() + bar.get_height()/2, \n",
    "            f'{importance:.3f}', ha='left', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Plot 2: Cumulative importance\n",
    "ax2 = axes[1]\n",
    "cumulative_importance = np.cumsum(importance_df['Importance'])\n",
    "ax2.plot(range(1, len(cumulative_importance) + 1), cumulative_importance, \n",
    "         'o-', linewidth=3, markersize=8, color='darkgreen')\n",
    "ax2.axhline(y=0.8, color='red', linestyle='--', alpha=0.7, linewidth=2)\n",
    "ax2.axhline(y=0.9, color='orange', linestyle='--', alpha=0.7, linewidth=2)\n",
    "ax2.set_xlabel('Number of Top Features')\n",
    "ax2.set_ylabel('Cumulative Importance')\n",
    "ax2.set_title('Cumulative Feature Importance')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim(0, 1.05)\n",
    "\n",
    "# Add annotations\n",
    "features_80 = np.argmax(cumulative_importance >= 0.8) + 1\n",
    "features_90 = np.argmax(cumulative_importance >= 0.9) + 1\n",
    "ax2.annotate(f'{features_80} features\\nâ†’ 80% importance', \n",
    "             xy=(features_80, 0.8), xytext=(features_80 + 1, 0.7),\n",
    "             arrowprops=dict(arrowstyle='->', color='red'),\n",
    "             fontsize=10, ha='center')\n",
    "ax2.annotate(f'{features_90} features\\nâ†’ 90% importance', \n",
    "             xy=(features_90, 0.9), xytext=(features_90 + 1, 0.95),\n",
    "             arrowprops=dict(arrowstyle='->', color='orange'),\n",
    "             fontsize=10, ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Feature Selection Insights:\")\n",
    "print(f\"  {features_80} features capture 80% of importance\")\n",
    "print(f\"  {features_90} features capture 90% of importance\")\n",
    "print(f\"  Could potentially reduce from {len(feature_names)} to {features_80} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permutation-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare impurity-based vs permutation importance\n",
    "print(\"=== IMPURITY vs PERMUTATION IMPORTANCE ===\")\n",
    "print()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Calculate permutation importance\n",
    "perm_importance = permutation_importance(\n",
    "    rf_importance, X_test, y_test, \n",
    "    n_repeats=10, random_state=42, scoring='accuracy'\n",
    ")\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Impurity_Importance': rf_importance.feature_importances_,\n",
    "    'Permutation_Importance': perm_importance.importances_mean,\n",
    "    'Perm_Std': perm_importance.importances_std\n",
    "}).sort_values('Impurity_Importance', ascending=False)\n",
    "\n",
    "print(\"Comparison of Importance Methods:\")\n",
    "print(\"Feature           | Impurity | Permutation | Diff\")\n",
    "print(\"-\" * 55)\n",
    "for _, row in comparison_df.iterrows():\n",
    "    diff = row['Permutation_Importance'] - row['Impurity_Importance']\n",
    "    print(f\"{row['Feature']:<15} | {row['Impurity_Importance']:.4f}   | {row['Permutation_Importance']:.4f}      | {diff:+.4f}\")\n",
    "\n",
    "# Visualize comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "x = range(len(comparison_df))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar([i - width/2 for i in x], comparison_df['Impurity_Importance'], \n",
    "        width, label='Impurity-based', alpha=0.8, color='lightblue')\n",
    "plt.bar([i + width/2 for i in x], comparison_df['Permutation_Importance'], \n",
    "        width, label='Permutation-based', alpha=0.8, color='lightcoral',\n",
    "        yerr=comparison_df['Perm_Std'], capsize=3)\n",
    "\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Impurity-based vs Permutation-based Feature Importance')\n",
    "plt.xticks(x, comparison_df['Feature'], rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "print(\"Key Differences:\")\n",
    "print(\"  Impurity-based: Fast, but can be biased toward high-cardinality features\")\n",
    "print(\"  Permutation-based: Slower, but shows actual predictive importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hyperparameters",
   "metadata": {},
   "source": [
    "## 5. Hyperparameter Tuning\n",
    "\n",
    "Random Forest has several important hyperparameters:\n",
    "\n",
    "### Key Hyperparameters:\n",
    "\n",
    "1. **n_estimators**: Number of trees\n",
    "   - More trees = better performance (up to a point)\n",
    "   - Typical range: 100-1000\n",
    "\n",
    "2. **max_features**: Features to consider per split\n",
    "   - 'sqrt': âˆš(n_features) - good default\n",
    "   - 'log2': logâ‚‚(n_features) - alternative\n",
    "   - integer: specific number\n",
    "\n",
    "3. **max_depth**: Maximum tree depth\n",
    "   - None: unlimited (default)\n",
    "   - integer: limit depth to prevent overfitting\n",
    "\n",
    "4. **min_samples_split**: Minimum samples to split a node\n",
    "   - Higher values prevent overfitting\n",
    "   - Default: 2\n",
    "\n",
    "5. **min_samples_leaf**: Minimum samples in leaf node\n",
    "   - Higher values smooth the model\n",
    "   - Default: 1\n",
    "\n",
    "6. **bootstrap**: Whether to use bootstrap sampling\n",
    "   - True: Standard Random Forest\n",
    "   - False: Use entire dataset for each tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hyperparameter-tuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate hyperparameter effects\n",
    "print(\"=== HYPERPARAMETER EFFECTS ANALYSIS ===\")\n",
    "print()\n",
    "\n",
    "# Test different numbers of estimators\n",
    "n_estimators_range = [10, 25, 50, 100, 200, 500]\n",
    "estimator_results = []\n",
    "\n",
    "print(\"Effect of Number of Estimators:\")\n",
    "for n_est in n_estimators_range:\n",
    "    rf = RandomForestClassifier(n_estimators=n_est, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    train_acc = accuracy_score(y_train, rf.predict(X_train))\n",
    "    test_acc = accuracy_score(y_test, rf.predict(X_test))\n",
    "    \n",
    "    estimator_results.append({\n",
    "        'n_estimators': n_est,\n",
    "        'train_acc': train_acc,\n",
    "        'test_acc': test_acc,\n",
    "        'overfitting': train_acc - test_acc\n",
    "    })\n",
    "    \n",
    "    print(f\"  {n_est:3d} trees: Train={train_acc:.3f}, Test={test_acc:.3f}, Gap={train_acc-test_acc:.3f}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Test different max_features\n",
    "max_features_options = ['sqrt', 'log2', 0.5, 0.8, None]\n",
    "features_results = []\n",
    "\n",
    "print(\"Effect of max_features:\")\n",
    "for max_feat in max_features_options:\n",
    "    rf = RandomForestClassifier(n_estimators=100, max_features=max_feat, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    train_acc = accuracy_score(y_train, rf.predict(X_train))\n",
    "    test_acc = accuracy_score(y_test, rf.predict(X_test))\n",
    "    \n",
    "    features_results.append({\n",
    "        'max_features': str(max_feat),\n",
    "        'train_acc': train_acc,\n",
    "        'test_acc': test_acc,\n",
    "        'overfitting': train_acc - test_acc\n",
    "    })\n",
    "    \n",
    "    actual_max_feat = rf.max_features_ if hasattr(rf, 'max_features_') else 'N/A'\n",
    "    print(f\"  {str(max_feat):<6}: Train={train_acc:.3f}, Test={test_acc:.3f}, Gap={train_acc-test_acc:.3f} (actual: {actual_max_feat})\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Test effect of tree depth\n",
    "max_depth_options = [3, 5, 10, 20, None]\n",
    "depth_results = []\n",
    "\n",
    "print(\"Effect of max_depth:\")\n",
    "for max_dep in max_depth_options:\n",
    "    rf = RandomForestClassifier(n_estimators=100, max_depth=max_dep, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    train_acc = accuracy_score(y_train, rf.predict(X_train))\n",
    "    test_acc = accuracy_score(y_test, rf.predict(X_test))\n",
    "    \n",
    "    depth_results.append({\n",
    "        'max_depth': str(max_dep),\n",
    "        'train_acc': train_acc,\n",
    "        'test_acc': test_acc,\n",
    "        'overfitting': train_acc - test_acc\n",
    "    })\n",
    "    \n",
    "    print(f\"  {str(max_dep):<6}: Train={train_acc:.3f}, Test={test_acc:.3f}, Gap={train_acc-test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-hyperparams",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize hyperparameter effects\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Plot 1: Number of Estimators\n",
    "ax1 = axes[0]\n",
    "est_df = pd.DataFrame(estimator_results)\n",
    "ax1.plot(est_df['n_estimators'], est_df['train_acc'], 'o-', label='Training Accuracy', linewidth=2)\n",
    "ax1.plot(est_df['n_estimators'], est_df['test_acc'], 's-', label='Test Accuracy', linewidth=2)\n",
    "ax1.set_xlabel('Number of Estimators')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_title('Effect of Number of Trees')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xscale('log')\n",
    "\n",
    "# Plot 2: Max Features\n",
    "ax2 = axes[1]\n",
    "feat_df = pd.DataFrame(features_results)\n",
    "x_pos = range(len(feat_df))\n",
    "ax2.bar([x - 0.2 for x in x_pos], feat_df['train_acc'], 0.4, label='Training', alpha=0.8)\n",
    "ax2.bar([x + 0.2 for x in x_pos], feat_df['test_acc'], 0.4, label='Test', alpha=0.8)\n",
    "ax2.set_xlabel('max_features')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('Effect of max_features')\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels(feat_df['max_features'], rotation=45)\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 3: Max Depth\n",
    "ax3 = axes[2]\n",
    "depth_df = pd.DataFrame(depth_results)\n",
    "x_pos = range(len(depth_df))\n",
    "ax3.bar([x - 0.2 for x in x_pos], depth_df['train_acc'], 0.4, label='Training', alpha=0.8)\n",
    "ax3.bar([x + 0.2 for x in x_pos], depth_df['test_acc'], 0.4, label='Test', alpha=0.8)\n",
    "ax3.set_xlabel('max_depth')\n",
    "ax3.set_ylabel('Accuracy')\n",
    "ax3.set_title('Effect of max_depth')\n",
    "ax3.set_xticks(x_pos)\n",
    "ax3.set_xticklabels(depth_df['max_depth'])\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key Insights:\")\n",
    "print(\"1. More trees generally improve performance (diminishing returns after ~100)\")\n",
    "print(\"2. sqrt(n_features) is usually optimal for max_features\")\n",
    "print(\"3. Unlimited depth works well for Random Forest (less overfitting than single trees)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oob-error",
   "metadata": {},
   "source": [
    "## 6. Out-of-Bag (OOB) Error\n",
    "\n",
    "Random Forest has a built-in validation mechanism: **Out-of-Bag Error**\n",
    "\n",
    "### How OOB Works:\n",
    "\n",
    "1. **Bootstrap Sampling**: Each tree uses ~63% of training data\n",
    "2. **OOB Samples**: Remaining ~37% are \"out-of-bag\" for that tree\n",
    "3. **OOB Prediction**: For each sample, use only trees that didn't see it during training\n",
    "4. **OOB Error**: Calculate error on these OOB predictions\n",
    "\n",
    "### Benefits:\n",
    "\n",
    "- **No separate validation set needed**\n",
    "- **Unbiased estimate** of generalization error\n",
    "- **Free cross-validation** during training\n",
    "- **Can monitor overfitting** as you add trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oob-demonstration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate Out-of-Bag error\n",
    "print(\"=== OUT-OF-BAG ERROR DEMONSTRATION ===\")\n",
    "print()\n",
    "\n",
    "# Train Random Forest with OOB scoring enabled\n",
    "rf_oob = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    oob_score=True,  # Enable OOB scoring\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_oob.fit(X_train, y_train)\n",
    "\n",
    "# Compare OOB score with test score\n",
    "oob_accuracy = rf_oob.oob_score_\n",
    "test_accuracy = accuracy_score(y_test, rf_oob.predict(X_test))\n",
    "train_accuracy = accuracy_score(y_train, rf_oob.predict(X_train))\n",
    "\n",
    "print(f\"Performance Comparison:\")\n",
    "print(f\"  Training Accuracy: {train_accuracy:.3f}\")\n",
    "print(f\"  OOB Accuracy:      {oob_accuracy:.3f}\")\n",
    "print(f\"  Test Accuracy:     {test_accuracy:.3f}\")\n",
    "print()\n",
    "print(f\"OOB vs Test difference: {abs(oob_accuracy - test_accuracy):.3f}\")\n",
    "print()\n",
    "print(\"Key Insight: OOB score closely approximates test performance!\")\n",
    "print(\"This means we can estimate generalization without a separate validation set.\")\n",
    "\n",
    "# Show OOB predictions for some samples\n",
    "oob_predictions = rf_oob.oob_decision_function_\n",
    "print(f\"\\nOOB predictions shape: {oob_predictions.shape}\")\n",
    "print(f\"(Each row is a training sample, each column is a class probability)\")\n",
    "\n",
    "# Show examples\n",
    "print(\"\\nSample OOB predictions:\")\n",
    "print(\"Sample | True | OOB Prob[Died] | OOB Prob[Survived] | OOB Prediction\")\n",
    "print(\"-\" * 70)\n",
    "for i in range(5):\n",
    "    true_label = y_train.iloc[i]\n",
    "    oob_pred_probs = oob_predictions[i]\n",
    "    oob_pred = np.argmax(oob_pred_probs)\n",
    "    print(f\"{i:4d}   | {true_label:2d}   | {oob_pred_probs[0]:11.3f} | {oob_pred_probs[1]:14.3f} | {oob_pred:11d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oob-vs-cv",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare OOB error with cross-validation\n",
    "print(\"=== OOB ERROR vs CROSS-VALIDATION ===\")\n",
    "print()\n",
    "\n",
    "# Test different numbers of estimators\n",
    "n_estimators_list = [10, 25, 50, 100, 200, 500]\n",
    "oob_scores = []\n",
    "cv_scores_mean = []\n",
    "cv_scores_std = []\n",
    "\n",
    "print(\"Comparison of OOB Error vs Cross-Validation:\")\n",
    "print(\"Trees | OOB Score | CV Score (5-fold)\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for n_est in n_estimators_list:\n",
    "    # OOB Score\n",
    "    rf = RandomForestClassifier(n_estimators=n_est, oob_score=True, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    oob_score = rf.oob_score_\n",
    "    \n",
    "    # Cross-validation Score  \n",
    "    rf_cv = RandomForestClassifier(n_estimators=n_est, random_state=42)\n",
    "    cv_scores = cross_val_score(rf_cv, X_train, y_train, cv=5)\n",
    "    cv_mean = cv_scores.mean()\n",
    "    cv_std = cv_scores.std()\n",
    "    \n",
    "    oob_scores.append(oob_score)\n",
    "    cv_scores_mean.append(cv_mean)\n",
    "    cv_scores_std.append(cv_std)\n",
    "    \n",
    "    print(f\"{n_est:3d}   | {oob_score:.3f}     | {cv_mean:.3f} (+/- {cv_std*2:.3f})\")\n",
    "\n",
    "# Visualize comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(n_estimators_list, cv_scores_mean, yerr=cv_scores_std, \n",
    "             label='5-Fold Cross-Validation', marker='o', capsize=5, linewidth=2)\n",
    "plt.plot(n_estimators_list, oob_scores, 'o-', \n",
    "         label='Out-of-Bag Score', linewidth=2, markersize=8)\n",
    "plt.xlabel('Number of Estimators')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.title('OOB Score vs Cross-Validation Score')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xscale('log')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = np.corrcoef(oob_scores, cv_scores_mean)[0, 1]\n",
    "print(f\"\\nCorrelation between OOB and CV scores: {correlation:.3f}\")\n",
    "print(f\"Mean absolute difference: {np.mean(np.abs(np.array(oob_scores) - np.array(cv_scores_mean))):.3f}\")\n",
    "print()\n",
    "print(\"Conclusion: OOB score provides a reliable estimate of model performance\")\n",
    "print(\"without the computational cost of cross-validation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advantages-limitations",
   "metadata": {},
   "source": [
    "## 7. Advantages and Limitations\n",
    "\n",
    "### âœ… Advantages\n",
    "\n",
    "1. **Excellent Performance**: Often achieves high accuracy out-of-the-box\n",
    "2. **Overfitting Resistance**: Much less prone to overfitting than single trees\n",
    "3. **Feature Importance**: Provides reliable feature importance estimates\n",
    "4. **Handles Missing Values**: Can handle missing data (with modifications)\n",
    "5. **No Feature Scaling**: Works with features on different scales\n",
    "6. **Parallel Training**: Trees can be trained in parallel\n",
    "7. **OOB Validation**: Built-in validation without separate test set\n",
    "8. **Robust to Outliers**: Ensemble averaging reduces outlier impact\n",
    "9. **Works with Mixed Data**: Handles both numerical and categorical features\n",
    "10. **Good Default Parameters**: Often works well without much tuning\n",
    "\n",
    "### âŒ Limitations\n",
    "\n",
    "1. **Memory Usage**: Requires more memory than single models\n",
    "2. **Prediction Speed**: Slower prediction than single models\n",
    "3. **Less Interpretable**: Harder to interpret than single decision trees\n",
    "4. **Biased to Majority Class**: Can be biased in imbalanced datasets\n",
    "5. **Overfitting with Noise**: Can still overfit with very noisy data\n",
    "6. **Feature Correlation**: Performance degrades with highly correlated features\n",
    "7. **Linear Relationships**: Not optimal for purely linear relationships\n",
    "8. **Extrapolation**: Cannot extrapolate beyond training data range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final comprehensive evaluation\n",
    "print(\"=== COMPREHENSIVE RANDOM FOREST EVALUATION ===\")\n",
    "print()\n",
    "\n",
    "# Create optimized Random Forest\n",
    "final_rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_features='sqrt',\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    oob_score=True,\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Use all cores\n",
    ")\n",
    "\n",
    "final_rf.fit(X_train, y_train)\n",
    "\n",
    "# Comprehensive evaluation\n",
    "evaluator = ModelEvaluator(\"Optimized Random Forest\")\n",
    "y_pred_final = final_rf.predict(X_test)\n",
    "y_proba_final = final_rf.predict_proba(X_test)\n",
    "\n",
    "metrics = evaluator.evaluate_classification(\n",
    "    y_test, y_pred_final, y_proba_final,\n",
    "    class_names=['Died', 'Survived']\n",
    ")\n",
    "\n",
    "evaluator.print_detailed_report()\n",
    "\n",
    "print(f\"\\nAdditional Random Forest Metrics:\")\n",
    "print(f\"  OOB Score: {final_rf.oob_score_:.3f}\")\n",
    "print(f\"  Number of Trees: {final_rf.n_estimators}\")\n",
    "print(f\"  Max Features per Split: {final_rf.max_features}\")\n",
    "\n",
    "# Individual tree performance analysis\n",
    "print(f\"\\nIndividual Tree Analysis:\")\n",
    "individual_accuracies = []\n",
    "for i, tree in enumerate(final_rf.estimators_[:10]):  # Check first 10 trees\n",
    "    tree_pred = tree.predict(X_test)\n",
    "    tree_acc = accuracy_score(y_test, tree_pred)\n",
    "    individual_accuracies.append(tree_acc)\n",
    "    if i < 5:  # Print first 5\n",
    "        print(f\"  Tree {i+1}: {tree_acc:.3f} accuracy\")\n",
    "\n",
    "print(f\"  Average single tree accuracy: {np.mean(individual_accuracies):.3f}\")\n",
    "print(f\"  Random Forest accuracy: {metrics['accuracy']:.3f}\")\n",
    "print(f\"  Ensemble improvement: {metrics['accuracy'] - np.mean(individual_accuracies):+.3f}\")\n",
    "\n",
    "# Memory and timing info\n",
    "import sys\n",
    "model_size = sys.getsizeof(final_rf) / (1024 * 1024)  # MB\n",
    "print(f\"\\nModel Statistics:\")\n",
    "print(f\"  Model size: {model_size:.2f} MB\")\n",
    "print(f\"  Total nodes: {sum(tree.tree_.node_count for tree in final_rf.estimators_)}\")\n",
    "print(f\"  Average tree depth: {np.mean([tree.tree_.max_depth for tree in final_rf.estimators_]):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## 8. Summary and Key Takeaways\n",
    "\n",
    "### ðŸŽ¯ What You've Learned\n",
    "\n",
    "1. **Ensemble Power**: Multiple weak learners create a strong learner\n",
    "2. **Two-Fold Randomness**: Bootstrap sampling + feature randomness\n",
    "3. **Bias-Variance Tradeoff**: How averaging reduces variance while maintaining low bias\n",
    "4. **Feature Importance**: Reliable importance estimates from ensemble averaging\n",
    "5. **OOB Error**: Built-in validation mechanism\n",
    "6. **Hyperparameter Effects**: How different parameters affect performance\n",
    "7. **Practical Implementation**: Real-world application and evaluation\n",
    "\n",
    "### ðŸš€ Next Steps\n",
    "\n",
    "1. **Advanced Ensembles**: Learn Gradient Boosting and XGBoost\n",
    "2. **Feature Engineering**: Create better features for tree-based models\n",
    "3. **Hyperparameter Optimization**: Use RandomizedSearchCV or Bayesian optimization\n",
    "4. **Imbalanced Data**: Learn techniques for handling class imbalance\n",
    "5. **Interpretability**: Explore SHAP values and partial dependence plots\n",
    "\n",
    "### ðŸ’¡ Key Insights\n",
    "\n",
    "- **Wisdom of Crowds**: Individual errors cancel out in ensemble averaging\n",
    "- **Randomness is Key**: Bootstrap + feature randomness creates diversity\n",
    "- **Less Overfitting**: Ensembles are more robust than individual models\n",
    "- **Feature Importance**: More reliable than single tree importance\n",
    "- **Good Defaults**: Often works well with minimal tuning\n",
    "- **OOB Validation**: Free performance estimation during training\n",
    "\n",
    "### ðŸ› ï¸ Best Practices\n",
    "\n",
    "1. **Start with Defaults**: 100 trees, sqrt(features), unlimited depth\n",
    "2. **Use OOB Score**: Monitor performance without validation set\n",
    "3. **Check Feature Importance**: Understand what drives predictions\n",
    "4. **Consider Memory**: More trees = more memory usage\n",
    "5. **Parallel Training**: Use n_jobs=-1 for faster training\n",
    "6. **Feature Selection**: Remove low-importance features if needed\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations!** You now understand Random Forest, one of the most powerful and widely-used machine learning algorithms. Random Forest demonstrates the power of ensemble learning and serves as an excellent foundation for understanding more advanced ensemble methods.\n",
    "\n",
    "Remember: Sometimes the best approach is to combine many simple models rather than building one complex model! ðŸŒ²"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}