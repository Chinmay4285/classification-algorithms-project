# Transformers (BERT)

## [TARGET] Algorithm Overview

Attention-based transformer model for text classification

## [CHART] Dataset Used

**IMDB Reviews**

## [PARAM] Key Parameters

```python
AutoModel(model_name="distilbert-base-uncased")
```

## üèÉ‚Äç‚ôÇÔ∏è Quick Start

```bash
cd 10_transformers
python train.py
```

Or explore the interactive notebook:
```bash
jupyter notebook explanation.ipynb
```

## [INFO] Expected Performance

- **Accuracy**: TBD (run training script)
- **Training Time**: TBD
- **GPU Memory Usage**: Optimized for RTX 3060 (6GB VRAM)

## [TOOL] Implementation Notes

This implementation is optimized for:
- NVIDIA RTX 3060 GPU (6GB VRAM)
- Efficient memory usage
- Fast training and inference
- Comprehensive evaluation metrics

See the training script and notebook for detailed analysis and results.
